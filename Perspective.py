import os
import requests
import json
import time
from pathlib import Path

# ==============================================================================
# âš™ï¸ 1. ì‚¬ìš©ì ì„¤ì •
# ==============================================================================
API_KEY = "AIzaSyABmHVA4Bqb_RZngFF1k1gXj_N4jXeqvKc"
BASE_PATH = r"C:\Users\82108\OneDrive\ë°”íƒ• í™”ë©´\4-2í•™ê¸°\ì¢…í•©ì„¤ê³„\Modern_Language_Api"  # ê¸°ë³¸ ê²½ë¡œ
FOLDERS = [0, 1, 2, 3, 4]     # í´ë” ë²ˆí˜¸
RESPONSES = list(range(1, 11)) # Response_1 ~ Response_10

# ==============================================================================
# âš™ï¸ 2. API í˜¸ì¶œ ë° ë¶„ì„ í•¨ìˆ˜
# ==============================================================================
def analyze_text_toxicity(api_key: str, text_to_analyze: str) -> dict:
    """Perspective APIë¥¼ REST APIë¡œ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ìœ í•´ì„± ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    url = "https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze"
    
    request_body = {
        'comment': {'text': text_to_analyze},
        'languages': ['ko', 'en'],
        'requestedAttributes': {
            'TOXICITY': {},
            'SEVERE_TOXICITY': {},
            'IDENTITY_ATTACK': {},
            'INSULT': {},
            'PROFANITY': {},
            'THREAT': {}
        }
    }
    
    try:
        response = requests.post(
            url,
            params={'key': api_key},
            json=request_body,
            timeout=10
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"    âŒ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

# ==============================================================================
# âš™ï¸ 3. ë°°ì¹˜ ë¶„ì„ í•¨ìˆ˜
# ==============================================================================
def batch_analyze():
    """ëª¨ë“  í´ë”ì˜ íŒŒì¼ì„ ìˆœíšŒí•˜ë©° ë¶„ì„í•©ë‹ˆë‹¤."""
    
    results_summary = []
    total_files = 0
    
    for folder_num in FOLDERS:
        folder_path = os.path.join(BASE_PATH, f"Harmful_Test_{folder_num}")
        
        # í´ë” ì¡´ì¬ í™•ì¸
        if not os.path.exists(folder_path):
            print(f"âš ï¸  í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
            continue
        
        print(f"\n{'='*70}")
        print(f"ğŸ“ í´ë”: {folder_path}")
        print(f"{'='*70}")
        
        for response_num in RESPONSES:
            file_path = os.path.join(folder_path, f"Response_{response_num}.txt")
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(file_path):
                print(f"  âš ï¸  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: Response_{response_num}.txt")
                continue
            
            total_files += 1
            
            # íŒŒì¼ ì½ê¸°
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text_content = f.read()
            except Exception as e:
                print(f"  âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ (Response_{response_num}): {e}")
                continue
            
            # API ë¶„ì„
            print(f"  ğŸ”¬ Response_{response_num}.txt ë¶„ì„ ì¤‘...", end=" ")
            analysis_result = analyze_text_toxicity(API_KEY, text_content)
            
            # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
            if analysis_result:
                scores = {}
                for attribute, data in analysis_result['attributeScores'].items():
                    score = data['summaryScore']['value']
                    scores[attribute] = score
                
                # ê°€ì¥ ë†’ì€ ì ìˆ˜ ì°¾ê¸°
                max_attr = max(scores, key=scores.get)
                max_score = scores[max_attr]
                
                print(f"âœ… (ìµœê³ : {max_attr} {max_score:.2%})")
                
                results_summary.append({
                    'file': file_path,
                    'scores': scores,
                    'max_attribute': max_attr,
                    'max_score': max_score
                })
            else:
                print(f"âŒ ë¶„ì„ ì‹¤íŒ¨")
            
            # API ìš”ì²­ ì œí•œì„ í”¼í•˜ê¸° ìœ„í•´ ì•½ê°„ì˜ ë”œë ˆì´ ì¶”ê°€
            time.sleep(1)
    
    return results_summary, total_files

# ==============================================================================
# âš™ï¸ 4. ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
# ==============================================================================
def print_results(results_summary, total_files):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    
    print(f"\n\n{'='*70}")
    print(f"ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼")
    print(f"{'='*70}")
    print(f"ì´ ë¶„ì„ íŒŒì¼ ìˆ˜: {total_files}")
    print(f"ë¶„ì„ ì™„ë£Œ íŒŒì¼ ìˆ˜: {len(results_summary)}")
    
    if not results_summary:
        print("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì†ì„±ë³„ í‰ê·  ì ìˆ˜
    print(f"\nğŸ¯ ì†ì„±ë³„ í‰ê·  ì ìˆ˜:")
    print("-" * 70)
    
    attributes = {}
    for result in results_summary:
        for attr, score in result['scores'].items():
            if attr not in attributes:
                attributes[attr] = []
            attributes[attr].append(score)
    
    for attr in sorted(attributes.keys()):
        avg_score = sum(attributes[attr]) / len(attributes[attr])
        print(f"  {attr:<20}: {avg_score:.2%}")
    
    # ìƒìœ„ ìœ„í—˜ íŒŒì¼
    print(f"\nâš ï¸  ìœ í•´ì„± ì ìˆ˜ê°€ ë†’ì€ ìƒìœ„ 5ê°œ íŒŒì¼:")
    print("-" * 70)
    
    sorted_results = sorted(results_summary, key=lambda x: x['max_score'], reverse=True)
    for i, result in enumerate(sorted_results[:5], 1):
        print(f"  {i}. {result['file']}")
        print(f"     {result['max_attribute']}: {result['max_score']:.2%}\n")
    
    # CSV íŒŒì¼ë¡œ ì €ì¥
    save_to_csv(results_summary)

def save_to_csv(results_summary):
    """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    
    import csv
    
    csv_file = "toxicity_analysis_results.csv"
    
    try:
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['File', 'TOXICITY', 'SEVERE_TOXICITY', 'IDENTITY_ATTACK', 'INSULT', 'PROFANITY', 'THREAT']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            
            writer.writeheader()
            for result in results_summary:
                row = {'File': result['file']}
                row.update(result['scores'])
                writer.writerow(row)
        
        print(f"\nâœ… ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {csv_file}")
    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")

# ==============================================================================
# âš™ï¸ 5. ë©”ì¸ ì‹¤í–‰
# ==============================================================================
if __name__ == "__main__":
    print("ğŸš€ ë°°ì¹˜ ìœ í•´ì„± ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“‚ ë¶„ì„ ëŒ€ìƒ: Harmful_Test_0 ~ Harmful_Test_4")
    print(f"ğŸ“„ ê° í´ë”ì˜ Response_1.txt ~ Response_10.txt\n")
    
    results_summary, total_files = batch_analyze()
    print_results(results_summary, total_files)
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")